{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T15:47:50.676290Z",
     "start_time": "2017-11-13T15:47:45.225664Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, Layer,\\\n",
    "                         ZeroPadding2D, Activation, Reshape, Permute, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "import matplotlib.pyplot as plt # to plot images\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T15:47:50.680433Z",
     "start_time": "2017-11-13T15:47:50.677285Z"
    }
   },
   "outputs": [],
   "source": [
    "train_and_val_dataset_file = 'datasets/dataset-1/train-and-val.pkl'\n",
    "test_dataset_file = 'datasets/dataset-1/test.pkl'\n",
    "saved_model_filename = \"datasets/dataset-1/test-segnet-{epoch:02d}-{val_dice_coef_accur:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-28T15:25:33.893434",
     "start_time": "2017-06-28T15:25:33.886889"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T15:47:53.642790Z",
     "start_time": "2017-11-13T15:47:50.975987Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(3, 128, 128, 1)\n",
      "(5, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(3, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "X_remaining, Y_remaining, remaining_dataset_desc = joblib.load(train_and_val_dataset_file)\n",
    "Xte, yte, test_dataset_desc = joblib.load(test_dataset_file) # X and y for test\n",
    "training_set_index = remaining_dataset_desc['training_set_index']\n",
    "validation_set_index = remaining_dataset_desc['validation_set_index']\n",
    "\n",
    "Xtr, ytr = X_remaining[:training_set_index,:], Y_remaining[:training_set_index] # X and y for training\n",
    "Xva, yva = X_remaining[training_set_index:validation_set_index,:], Y_remaining[training_set_index:validation_set_index] # X and y for validation\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Xva.shape)\n",
    "print(Xte.shape)\n",
    "print(ytr.shape)\n",
    "print(yva.shape)\n",
    "print(yte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-09T14:52:12.718813Z",
     "start_time": "2017-07-09T14:52:11.827824Z"
    }
   },
   "source": [
    "### Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T15:48:16.941018Z",
     "start_time": "2017-11-13T15:48:15.622173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(3, 128, 128, 1)\n",
      "(5, 128, 128, 1)\n",
      "(1, 128, 128, 1)\n",
      "(3, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing in the training set (mean and sd) and apply it to all sets\n",
    "\n",
    "full_image_mean_value = Xtr.mean() # mean-value for each pixel of all full images\n",
    "full_image_sd = Xtr.std() # standard deviation for each pixel of all full images\n",
    "\n",
    "Xtr = (Xtr - full_image_mean_value) / full_image_sd\n",
    "Xva = (Xva - full_image_mean_value) / full_image_sd\n",
    "Xte = (Xte - full_image_mean_value) / full_image_sd\n",
    "\n",
    "\"\"\"Xtr = Xtr.reshape((Xtr.shape[-1], Xtr.shape[1], Xtr.shape[2], Xtr.shape[0]))\n",
    "ytr = ytr.reshape((ytr.shape[-1], ytr.shape[1], ytr.shape[2], ytr.shape[0]))\n",
    "\n",
    "Xva = Xva.reshape((Xva.shape[-1], Xva.shape[1], Xva.shape[2], Xva.shape[0]))\n",
    "yva = yva.reshape((yva.shape[-1], yva.shape[1], yva.shape[2], yva.shape[0]))\n",
    "\n",
    "Xte = Xte.reshape((Xte.shape[-1], Xte.shape[1], Xte.shape[2], Xte.shape[0]))\n",
    "yte = yte.reshape((yte.shape[-1], yte.shape[1], yte.shape[2], yte.shape[0]))\"\"\"\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Xva.shape)\n",
    "print(Xte.shape)\n",
    "print(ytr.shape)\n",
    "print(yva.shape)\n",
    "print(yte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T15:49:12.090878Z",
     "start_time": "2017-11-13T15:49:12.066696Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "K.set_image_data_format('channels_last')  # TF dimension\n",
    "_, *input_image_shape, _ = Xtr.shape\n",
    "input_image_shape = tuple(input_image_shape)\n",
    "print(input_image_shape)\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "use_dropout = True\n",
    "use_regularizers = True\n",
    "dropout_rate = 0.5\n",
    "number_of_epochs = 1000\n",
    "batch_size = 32\n",
    "kernel_size = (5, 5)\n",
    "initial_volume_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T18:07:40.403398",
     "start_time": "2017-06-30T18:07:40.398392"
    }
   },
   "source": [
    "### Define Segnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T15:49:15.452221Z",
     "start_time": "2017-11-13T15:49:14.825624Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128, 128, 1)\n",
      "(?, 130, 130, 1)\n",
      "(?, 128, 128, 64)\n",
      "(?, 128, 128, 64)\n",
      "(?, 128, 128, 64)\n",
      "(?, 64, 64, 64)\n",
      "128\n",
      "2\n",
      "256\n",
      "(?, 128, 128, 2)\n",
      "(?, 2, 16384)\n",
      "(?, 16384, 2)\n",
      "Size of the CNN: 5466178\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "kernel = 3\n",
    "filter_size = 64\n",
    "pad = 1\n",
    "pool_size = 2\n",
    "input_height = 128\n",
    "input_width = 128\n",
    "nClasses = 2\n",
    "\n",
    "\n",
    "inputs = Input(shape=(*input_image_shape, 1))\n",
    "print(inputs.shape)\n",
    "x = ZeroPadding2D(padding=(pad,pad))(inputs)\n",
    "print(x.shape)\n",
    "x = Conv2D(filter_size, (kernel, kernel), padding='valid')(x)\n",
    "print(x.shape)\n",
    "x = BatchNormalization()(x)\n",
    "print(x.shape)\n",
    "x = Activation('relu')(x)\n",
    "print(x.shape)\n",
    "x = MaxPooling2D(pool_size=(pool_size, pool_size))(x)\n",
    "print(x.shape)\n",
    "\n",
    "x = ZeroPadding2D(padding=(pad,pad))(x)\n",
    "x = Conv2D(128, (kernel, kernel), padding='valid')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(pool_size, pool_size))(x)\n",
    "\n",
    "x = ZeroPadding2D(padding=(pad,pad))(x)\n",
    "x = Conv2D(256, (kernel, kernel), padding='valid')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(pool_size, pool_size))(x)\n",
    "\n",
    "x = ZeroPadding2D(padding=(pad,pad))(x)\n",
    "x = Conv2D(512, (kernel, kernel), padding='valid')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = ZeroPadding2D(padding=(pad,pad))(x)\n",
    "x = Conv2D(512, (kernel, kernel), padding='valid')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = UpSampling2D(size=(pool_size,pool_size))(x)\n",
    "x = ZeroPadding2D(padding=(pad,pad))(x)\n",
    "x = Conv2D(256, (kernel, kernel), padding='valid')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = UpSampling2D(size=(pool_size,pool_size))(x)\n",
    "x = ZeroPadding2D(padding=(pad,pad))(x)\n",
    "x = Conv2D(128, (kernel, kernel), padding='valid')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = UpSampling2D(size=(pool_size,pool_size))(x)\n",
    "x = ZeroPadding2D(padding=(pad,pad))(x)\n",
    "x = Conv2D(filter_size, (kernel, kernel), padding='valid')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D( nClasses , (1, 1), padding='valid')(x)\n",
    "\n",
    "print(x.shape[-2])\n",
    "print(x.shape[-1])\n",
    "print(x.shape[-2] * x.shape[-1] )\n",
    "\n",
    "print(x.shape)\n",
    "x = Reshape(( nClasses ,  128 * 128   ), input_shape=( nClasses , x.shape[-2], x.shape[-1]  ))(x)\n",
    "print(x.shape)\n",
    "x = Permute((2, 1))(x)\n",
    "print(x.shape)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[x])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer= Adam(lr=1e-5) , metrics=['accuracy'] )\n",
    "\n",
    "# Options for the model\n",
    "print(\"Size of the CNN: %s\" % model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-13T15:50:30.944Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_142 to have 3 dimensions, but got array with shape (5, 128, 128, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-f195c7bb003e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model.fit(Xtr, ytr, batch_size=batch_size, epochs=number_of_epochs, verbose=2, shuffle=True,\n\u001b[0;32m----> 4\u001b[0;31m              callbacks=[model_checkpoint], validation_data=(Xva, yva))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1638\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1485\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1488\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1489\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/miniconda3/envs/thesis/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_142 to have 3 dimensions, but got array with shape (5, 128, 128, 1)"
     ]
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(saved_model_filename, monitor='accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(Xtr, ytr, batch_size=batch_size, epochs=number_of_epochs, verbose=2, shuffle=True,\n",
    "             callbacks=[model_checkpoint], validation_data=(Xva, yva))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T17:01:09.942444Z",
     "start_time": "2017-11-10T17:01:09.932687Z"
    }
   },
   "outputs": [],
   "source": [
    "x = history.history['dice_coef_accur']\n",
    "y = history.history['val_dice_coef_accur']\n",
    "plt.plot(x, label='train')\n",
    "plt.plot(y, label = 'val')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "x = history.history['loss']\n",
    "y = history.history['val_loss']\n",
    "plt.plot(x, label='train')\n",
    "plt.plot(y, label='val')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T17:01:25.497969Z",
     "start_time": "2017-11-10T17:01:19.816771Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loss, accuracy_test = model.evaluate(Xte, yte, verbose=0)\n",
    "print(\"Training Accuracy Mean: \"+str(np.array(history.history['dice_coef_accur']).mean()))\n",
    "print(\"Validation Accuracy Mean: \"+str(np.array(history.history['val_dice_coef_accur']).mean()))\n",
    "print(\"Test Accuracy Mean: \"+str(accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict masks using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T17:02:18.041192Z",
     "start_time": "2017-11-10T17:02:08.263219Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"datasets/dataset-1/test-6-08-0.0069.hdf5\")\n",
    "test_loss, accuracy_test = model.evaluate(Xte, yte, verbose=0)\n",
    "print(\"Test Accuracy Mean: \"+str(accuracy_test))\n",
    "imgs_mask_test = model.predict(Xte, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-30T18:13:17.713578",
     "start_time": "2017-06-30T18:13:17.708972"
    }
   },
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T17:02:29.387711Z",
     "start_time": "2017-11-10T17:02:23.113010Z"
    }
   },
   "outputs": [],
   "source": [
    "ncols = 3 # number of columns in final grid of images\n",
    "nrows = 30 # looking at all images takes some time\n",
    "_, axes = plt.subplots(nrows, ncols, figsize=(17, 17*nrows/ncols))\n",
    "for axis in axes.flatten():\n",
    "    axis.set_axis_off()\n",
    "    axis.set_aspect('equal')\n",
    "\n",
    "for k in range(0, nrows):\n",
    "    im_test_original = Xte[k].reshape(*input_image_shape)\n",
    "    im_result = imgs_mask_test[k].reshape(*input_image_shape)\n",
    "    im_ground_truth = yte[k].reshape(*input_image_shape)\n",
    "    \n",
    "    axes[k, 0].set_title(\"Original Test Image\")\n",
    "    axes[k, 0].imshow(im_test_original, cmap='gray')\n",
    "    \n",
    "    axes[k, 1].set_title(\"Ground Truth\")\n",
    "    axes[k, 1].imshow(im_ground_truth, cmap='gray')\n",
    "    \n",
    "    axes[k, 2].set_title(\"Predicted\")\n",
    "    axes[k, 2].imshow(im_result, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
